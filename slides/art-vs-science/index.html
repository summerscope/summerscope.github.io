<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Art vs Science</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<!-- TO DO  - highlight colors improve. Highlight important words on text only screens -->
			<div class="slides">
				<section data-background-image="img/art-vs-science.jpg">
				</section>
				<section>
					<h2>UX Research</h2>
					<p><em>in the age of the reproducibility crisis</em></p>
				</section>
				<section>
					<h2>First, there was TED</h2>
					<p class="fragment"><small><a href="https://www.ted.com/talks/amy_cuddy_your_body_language_shapes_who_you_are" target="_blank">ted.com/talks/amy_cuddy_your_body_language_shapes_who_you_are</a></small></p>
					<aside class="notes">So back in 2012 there was a TED talk which propelled a social psychologist, Amy Cuddy, into a certain kind of fame. It's had over 51 million views and is one of the most popular talks on their site.</aside>			
				</section>
				<section data-background-image="img/power-pose.jpg">
					<aside class="notes">She claimed that standing in a particular pose for 2 minutes a day could make you more successful. This became known as the power pose.</aside>
				</section>
				<section>
					<h2>Field study</h2>
					<aside class="notes">Her claims were based on a field study she conducted which measured self-reported feelings of power, observed risk taking + cortisol and testosterone levels from a sample of 42. Participants stood in two poses for a minute each - half in power poses, the others in non-power (weak) poses.</aside>
				</section>
				<section data-background-image="img/high-power.png">
					<p class="fragment">High power poses</p>
					<aside class="notes">The two high power poses 1/2 participants held</aside>
				</section>
				<section data-background-image="img/low-power.png">
					<p class="fragment">Low power poses</p>
					<aside class="notes">The two low power poses 1/2 participants held</aside>
				</section>
				<section data-background-image="img/research-debunked.jpg">
					<aside class="notes">But then this happened. A study failed to reproduce her findings on hormone changes. just as spectacularly as her work had been lauded, now everyone rushed to dubunk it</aside>
				</section>
				<section>
					<ul>
						<small>
							<li><a href="http://fortune.com/2016/10/02/power-poses-research-false/" target="_blank">fortune.com/2016/10/02/power-poses-research-false/</a></li>
							<li><a href="http://time.com/4949675/power-poses-confidence/" target="_blank">time.com/4949675/power-poses-confidence/</a></li>
							<li><a href="https://www.nytimes.com/2017/10/18/magazine/when-the-revolution-came-for-amy-cuddy.html" target="_blank">nytimes.com/2017/10/18/magazine/when-the-revolution-came-for-amy-cuddy.html</a></li>
							<li><a href="https://www.sciencedaily.com/releases/2017/09/170911095932.htm" target="_blank">sciencedaily.com/releases/2017/09/170911095932.htm</a></li>
							<li><a href="https://journals.sagepub.com/doi/full/10.1177/0956797614553946" target="_blank">https://journals.sagepub.com/doi/full/10.1177/0956797614553946</a></li>
							<li><a href="https://www.forbes.com/sites/kimelsesser/2018/04/03/power-posing-is-back-amy-cuddy-successfully-refutes-criticism/#3c9a913c3b8e" target="_blank">forbes.com/sites/kimelsesser/2018/04/03/power-posing-is-back-amy-cuddy-successfully-refutes-criticism/#3c9a913c3b8e</a></li>
						</small>
					</ul>
				</section>
				<section>
					<blockquote>"...the idea became a shorthand for flashy social psychological work that could not be&nbsp;replicated..."</blockquote>
					<p><small><a href="https://www.tandfonline.com/doi/full/10.1080/23743603.2017.1309876?scroll=top&needAccess=true" target="_blank">tandfonline.com/doi/full/10.1080/23743603.2017.1309876?scroll=top&needAccess=true</a></small></p>
					<aside class="notes">More pop than science</aside>
				</section>
				<section>
					Reproducibility crisis
					<aside class="notes">In 2011 a movement started growing challenging the status quo in science. Asks whether enough work is being done to independently validate published results.</aside>
				</section>
				<section>
					<h2>Reproducibility project</h2>
					<aside class="notes">Started in Nov 2011 by Brian Nosek of Open Science Foundation. This issue has been raised before. Feynman 1970s - Cargo Cult lecture. </aside>
				</section>
				<section>
					You'll never believe what happened when scientists attempted to replicate 100 experiments...
					<p class="fragment grow"><em>Just wait til you see their results</em></p>
					<aside class="notes">Psychologists tried to recreate the experiments conducted by 100 studies, all published recently in academic journals.</aside>
				</section>
				<section>
					<blockquote>
						"<b>97%</b> of the original results showed a statistically significant effect, this was reproduced in only <b>36%</b> of the replication attempts"
					</blockquote>
					<small><a href="https://digest.bps.org.uk/2015/08/27/this-is-what-happened-when-psychologists-tried-to-replicate-100-previously-published-findings/" target="_blank">https://digest.bps.org.uk/</a></small>
					<aside class="notes">To stay as true as they could the group went through extensive measures to remain true to the original studies, to the extent of consulting the original authors</aside>
				</section>
				<section>
					<p>How did studies fail to reproduce?</p>
					<ol>
						<li class="fragment">False negatives</li>
						<li class="fragment">False positives</li>
						<li class="fragment">Different effect sizes</li>
					</ol>
				</section>
				<!-- <section>
					<iframe width="746" height="420" src="https://www.youtube-nocookie.com/embed/0Rnq1NpHdmw?start=20" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
				</section> -->
				<!-- <section>
					<a href="https://twitter.com/protohedgehog/status/1100079073466990593?s=21" target="_blank"><img class="plain" src="img/first-vs-right.jpg" width="500" /></a>	
				</section> -->
				<!-- <section data-background-image="img/nypost.jpg">
				</section>
				<section>
					<p><a href="https://nypost.com/2017/10/27/sniffing-your-partners-farts-could-help-ward-off-disease/" target="_blank">https://nypost.com/2017/10/27/sniffing-your-partners-farts-could-help-ward-off-disease/</a></p>
				</section> -->
				<section>
					<h2>What's to blame?</h2>
					<ul>
						<li class="fragment">"Publish or perish"</li>
						<li class="fragment">P-hacking</li>
						<li class="fragment">No replication studies</li>
						<li class="fragment">Clickbait</li>
					</ul>			
					<aside class="notes">Scientific research in it's worst form: shitty, low-powered studies designed to be over-stated as click-bait titles and turned into scientific CV catnip</aside>
				</section>
				<section>
					<h2>P-hacking</h2>
					<img src="img/funnel_shanks.png" width="400px" />
					<p><small><a href="http://blogs.discovermagazine.com/neuroskeptic/2015/11/10/reproducibility-crisis-the-plot-thickens/#.XKv_2Ov7TUJ" target="_blank">blogs.discovermagazine.com/neuroskeptic/2015/11/10/reproducibility-crisis-the-plot-thickens/#.XKv_2Ov7TUJ</a></small></p>
					<aside class="notes">Another way of expressing this would be to say that p values just below 0.05 are overrepresented. The published results ‚Äúhug‚Äù the p = 0.05 significance line. So each of the studies tended to report an effect just strong enough to be statistically significant. It‚Äôs very difficult to see how such a pattern could arise ‚Äì except through bias.</aside>
				</section>
				<section>
					But why does reproducibility even matter in UXR?
					<aside class="notes">Get buy in for real change.</aside>
				</section>
				<section class="references">
					<!-- Avoid becoming company clickbait  -->
					<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">&quot;But we did &#39;User Testing&#39;&quot;<br>Why testing prototypes won&#39;t validate your product ideas.<a href="https://t.co/AIeSNdRWfs">https://t.co/AIeSNdRWfs</a></p>&mdash; Cameron Rogers (@cameron_rogers) <a href="https://twitter.com/cameron_rogers/status/1111381603530366979?ref_src=twsrc%5Etfw">March 28, 2019</a></blockquote>

					<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It is entirely possible to do a tonne of research and keep heading in the wrong direction. It is not about volume or speed of research, it is about making sure you&#39;re looking for the right things in the right places. Please use great caution if your purpose is validation.</p>&mdash; Leisa Reichelt (@leisa) <a href="https://twitter.com/leisa/status/1111005587960029184?ref_src=twsrc%5Etfw">March 27, 2019</a></blockquote>

					<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">A lot of UX <a href="https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw">#research</a> looks to me like: ‚ÄúWell we gave users two hammers and lo and behold, they pounded nails, but they pounded nails differently.‚Äù</p>&mdash; Ha Phan (@hpdailyrant) <a href="https://twitter.com/hpdailyrant/status/1113110094382678016?ref_src=twsrc%5Etfw">April 2, 2019</a></blockquote>

					<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">It doesn&#39;t matter how much research you do if you haven&#39;t laid the foundation for evidence-based decision-making in advance. <br><br>Plenty of organizations pay for research, ignore it, and use that as the reason why research is a waste of resources.</p>&mdash; Erika Hall (@mulegirl) <a href="https://twitter.com/mulegirl/status/1110931323311448071?ref_src=twsrc%5Etfw">March 27, 2019</a></blockquote>

					<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

					<!--TODO: Add an illustration or more info here-->
					<aside class="notes">UX Research is plagued by overgeneralisation and mismatches in tool / problem space. It's incredibly important to be specific about the things you can learn from any given research method</aside>
				</section>
				<section>

				</section>

				<section>
					<p>So, should <span class="highlight-green">UX Research</span> be reproducible?</p>
					<h2 class="fragment">My answer is...</h2>
					<aside class="notes">I'm just going to skip to the end and tell you my take!</aside>
				</section>
				<section>
					<h1>Sometimes!<sup class="fragment">*</sup></h1>
					<p class="fragment"><sup>*</sup>It depends</p>
					<aside class="notes">My spicy hot take!</aside>
				</section>
	
				<!-- <section>
					So, how do we define <em>reproducible</em>?
					<aside class="notes">To explore it we need to unpack the question more, and ask ourselves what we mean by reproducible </aside>
				</section> -->
				<section>
					At least three levels to reproducibility
				</section>
				<section>
					<h2>1. Experiment design</h2>
					<ul>
						<li class="fragment">Methodology</li>
						<li class="fragment">Model</li>
						<li class="fragment">Sample size</li>
						<li class="fragment">Sample selection</li>
					</ul>
					<aside class="notes">Can I reproduce your experiment?  As in methodology, model, sample set, sample size, research variables, etc</aside>
				</section>
				<section>
					<h2>2. Data captured</h2>
					<aside class="notes">Do I get equivalent results? As in raw data </aside>
				</section>
				<section>
					<h2>3. Interpretation</h2>
					<aside class="notes">Do I interpret the data the same way? As in do I draw the same conclusions from the raw data  </aside>
				</section>
				<section>
					<blockquote>
						"I literally wake up in the middle of the night worrying about the incredible hubris of thinking that we UX'rs can do better than scientists. Interpreting data is hard. Identifying statistical significance is hard."
					</blockquote>
					<p><small>-Laura Summers (all the damn time)</small></p>
					<aside class="notes">Yep this is a common refrain for UX researchers - that we suffer FOMO, lack of confidence, general fear of not being scientific enough</aside>
				</section>
				<section>
					<blockquote>
						"UX research as a field suffers from a deep sense of paranoia about not appearing scientific enough."
					</blockquote>
					<p><small>- <a href="https://www.fastcompany.com/3055816/from-airbnb-the-real-value-of-ux-research" target="_blank">fastcompany.com/3055816/from-airbnb-the-real-value-of-ux-research</a></small></p>
				</section>
				<section>
					But UXR has different goals to Science
					<p class="fragment"><small>I hear you say!</small></p>
					<aside class="notes">This is TRUE</aside>
				</section>
				<section>
					<img class="plain" style="background:none;" src="img/crystal.png" width="300">
					<h1>Science</h1>
					<p class="fragment">Chipping away at the crystal of knowledge</p>
					<aside class="notes">Scientific research: in it's purest form, a pursuit to chip off a small shard off the crystal of knowledge</aside>
				</section>
				<section>
					<img class="plain" style="background:none;" src="img/risk.png" width="300">
					<h1>UXR</h1>
					<p class="fragment">Reducing business risk</p>
					<aside class="notes">UX research: in it's purest form, a pursuit to reduce risk and help a team intimately understand the people using their product </aside>
				</section>
				<section>
					<h2>UX Research types</h2>
					<p class="fragment">Qualitative -vs- Quantitative</p>
					<aside class="notes">Depending on the type of research, we may not even be striving for 'statistical significance'</aside>
				</section>
				<section data-background-image="img/qual-vs-quant.jpg">
				</section>
				<section>
					<h2>Qualitative</h2>
					<ol>
						<li class="fragment">Experiment design <span class="fragment highlight-green">‚úî</span> </li>
						<li class="fragment">Data captured <span class="fragment highlight-red">√ó</span> </li>
						<li class="fragment">Interpretation <span class="fragment highlight-red">√ó</span> </li>
					</ol>
					<aside class="notes">So when we capture small data samples and deep dive qualitative data, we don't expect to reproduce the same exact results because PEOPLE </aside>
				</section>
				<section>
					<h2>Quantitative</h2>
					<ol>
						<li class="fragment">Experiment design <span class="fragment highlight-green">‚úî</span></li>
						<li class="fragment">Data captured <span class="fragment highlight-green">‚úî</span></li>
						<li class="fragment">Interpretation <span class="fragment highlight-green">‚úî</span></li>
						<li class="fragment"><em>Hopefully</em> ü§û</li>
					</ol>
					<aside class="notes">But when we are doing AB tests or data driven tests into engagement, we should theoretically expect to be able to reproduce all aspects of that test </aside>
				</section>
				<!-- <section>
					Qualitative/Quantitative <br /><em>is not</em> <br />Statistically significant/Not statistically significant
					<aside class="notes">
						Note qual / quant as a binary doesn't technically fall on the does / doesn't have statistical significance binary. 
						You might technically have a qual study which had enough subjects for statistical significance but this almost never will be possible due to time and budgetary constraints.
					</aside>
				</section>
				<section>
					Sometimes you're on the cusp
					<aside class="notes">
						More importantly you might consider if you are collecting quant data but not in enough volume for statistical significance. 
					</aside>
				</section> -->

				<!-- 
				Add agenda? 
				<section>
					<h2>Learning goals</h2>
					<ol>
						<li class="fragment">What is the reproducibility crisis ‚úî</li>
						<li class="fragment">Why does it matter for UXR ‚úî </li>
						<li class="fragment">How to do it better </li>
					</ol>
					<aside class="notes"></aside>
				</section> -->

				<section>
					<h2>How do we do it better?</h2>
					<p class="fragment shrink"><em>Within the constraints of our current workplaces...</em></p>
					<aside class="notes"></aside>
				</section>

				<section>
					<h2>Any UX Research</h2>
					<aside class="notes"></aside>
				</section>
				<section>
					<p>Define your study <br /><em>before</em> <br>you start</p>
					<aside class="notes">Is it qual or quant? Are you looking for statistical significance or not? </aside>
				</section>
				<section>
					<p>Consider replication studies</p>
					<aside class="notes">do the same thing again! Even with qual data this is handy. Markets change. The zeitgeist changes. Your target users will change. Maybe a year apart, maybe with different UXrs</aside>
				</section>
				<section>
					<p>Preregistration</p>
					<aside class="notes">This could be an open souce and public initiative. If this is too hard a sell, even making this visible and shared within your company is a great idea.</aside>
				</section>
				<section>
					Open science movement
					<p class="fragment">What more can UXR learn/steal from the scientists?</p>
					<aside class="notes">This movement is epitomised by OSM which is pressing for scientists to share research models and design earlier (before data are captured)</aside>
				</section>
				<section>
					<p>Plan for null results</p>
					<aside class="notes">If you're working with statistical significance, know that sometimes the result will be that you don't know! Even with qual data sometimes you'll have lots of scattered signals but no clear signal from the noise.</aside>
				</section>

				<!-- 
				If time allows	
				<section>
					Open science movement
					<aside class="notes">This movement is epitomised by OSM which is pressing for scientists to share research models and design earlier (before data are captured)</aside>
				</section> -->


				<!-- TO DO  - breakdown into difference between all UXR and quant / data driven UXR looking for -->

				<section>
					<h2>UX Research</h2>
					<p>Which is attempting to identify statistically significant change</p>
					<aside class="notes"></aside>
				</section>

				<section>
					<p>Work on your research design hygiene</p>
					<aside class="notes">Identify your variables. Don't tweak them once the test has started. pre-test probability / bayesian probability is an interesting rabbit hole for those who want to skill up</aside>
				</section>
				<section>
					<h2>Is it statistically significant?</h2>
					<p class="fragment">Get better at understanding the strength of your signal</p>
					<aside class="notes"></aside>
				</section>
				<section>
					<h2>Resources</h2>
					<ul>
						<li><a href="https://splitly.com/statistical-calculator/" target="_blank">splitly.com/statistical-calculator</a></li>
						<li><a href="https://abtestguide.com/calc/" target="_blank">abtestguide.com/calc</a></li>
						<li><a href="https://vwo.com/ab-split-test-significance-calculator/" target="_blank">vwo.com/ab-split-test-significance-calculator/</a></li>
						<li><a href="https://neilpatel.com/ab-testing-calculator/" target="_blank">neilpatel.com/ab-testing-calculator/</a></li>
						<li><a href="https://www.surveymonkey.com/mp/ab-testing-significance-calculator/" target="_blank">surveymonkey.com/mp/ab-testing-significance-calculator/</a></li>
					</ul>
					<aside class="notes"></aside>
				</section>
				

				<!-- 
				<section>
					XXX
					<aside class="notes"></aside>
				</section>
				<section>
					XXX
					<aside class="notes"></aside>
				</section>
				<section>
					XXX
					<aside class="notes"></aside>
				</section> 
				-->
				
				<section data-background-image="img/capture-the-stars.jpg">
					<h1>Forward</h1>
					<p class="fragment">For UXR &amp; Science</p>
				</section>
				<section>
					<blockquote>"In short, be sceptical, pick a good question, and try to answer it in many ways. It takes many numbers to get close to the truth."</blockquote>
					<p><small>- <a href="https://www.nature.com/articles/d41586-019-00874-8" target="_blank">It‚Äôs time to talk about ditching statistical significance</a></small></p>
					<aside class="notes">To close, I think this quote summarises a great way forward for both science and UX</aside>
				</section>
				<section>
					<h2>Further reading</h2>
					<div class="references">
						<p><a href="https://en.wikipedia.org/wiki/Reproducibility_Project" target="_blank">Wikipedia - Reproducibility Project </a></p>
						<p><a href="https://en.wikipedia.org/wiki/Null_result" target="_blank">Wikipedia - Null Result</a></p>
						<p><a href="https://digest.bps.org.uk/2014/05/20/a-replication-tour-de-force/" target="_blank">A replication tour de force</a></p>
						<p><a href="https://fivethirtyeight.com/features/psychologys-replication-crisis-has-made-the-field-better/" target="_blank">Five Thirty-eight</a></p>
						<p><a href="https://www.ncbi.nlm.nih.gov/pubmed/16060722" target="_blank">Why most published research findings are false</a></p>
						<p><a href="https://www.wired.com/2017/01/john-arnold-waging-war-on-bad-science/" target="_blank">John Arnold waging war on bad science</a></p>
						<p><a href="http://calteches.library.caltech.edu/51/2/CargoCult.htm" target="_blank">"Cargo Cult Science" by Richard Feynman</a></p>
						<p><a href="https://medium.com/mule-design/the-9-rules-of-design-research-1a273fdd1d3b" target="_blank">The 9 Rules of Design Research</a></p>
					</div>					
				</section>
				<section>
					<h2>Resources</h2>
					<div class="references">
						<p><a href="https://cos.io/" target="_blank">Center for Open Science</a></p>
						<p><a href="https://osf.io/" target="_blank">Open Science Foundation</a></p>
					</div>					
				</section>
				<section>
					<h1>Thanks!</h1>
					<p>Get the slides<br />
					<a href="https://summerscope.github.io/slides/art-vs-science/" target="_blank">summerscope.github.io/slides/art-vs-science</a></p>
				</section>
			</div>

			<div class="twitter">
				<a href="https://twitter.com/summerscope" target="_blank">@summerscope</a>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.configure({ 
				slideNumber: true,
				slideNumber: 'c/t',
				transition: 'zoom'
			});

			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
