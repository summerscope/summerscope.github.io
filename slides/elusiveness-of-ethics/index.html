<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>The elusiveness of ethics: encoding fairness in an unfair world</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background-image="img/Tactile_3.jpg">
					<h1>The elusiveness of ethics</h1> 
					<h3>Encoding fairness in an unfair world</h3>
				</section>
				<section>
					<h2>Agenda</h2>
					<ol>
						<li><strong>Talk</strong> (40 minutes)</li>
						<li><strong>Q &amp; A</strong> (10 minutes)</li>
						<li><strong>Break</strong> (5-10 minutes)</li>
						<li><strong>Activity</strong> (25-30 minutes)</li>
					</ol>
				</section>
				<section>
					<h2>About me</h2>
					<img class="plain" src="img/foundress.png" height="400px" />
					<aside class="notes">About me -  background, learning deep learning & ML, reading papers, Fair ML reading group</aside>
				</section>
				<section>
					<h2>Slides</h2>
					<p><small><a href="http://summerscope.github.io/slides/elusiveness-of-ethics" target="_blank">summerscope.github.io/slides/elusiveness-of-ethics</a></small></p>
					<aside class="notes">Links all live, don't stress about trying to write down URLs</aside>
				</section>
				<section>
					<section>
						<h1>Section 1</h1>
						<h3 class="fragment">Setting the scene</h3>
					</section>
					<section>
						<h2>Once upon a time, in a<br />
							FinTech startup...</h2>
						<aside class="notes">Time I worked at a robo investor. We had a risk appetite quiz - women locked out of top risk portfolio...</aside>
					</section>
					<section>
						<h2>Descriptive <br> -vs- <br> Normative</h2>
					</section>
					<section data-background-image="img/mean-girls.jpg">
						<h2>Girls wear pink</h2>
						<h3 class="fragment">(Descriptive)</h3>
					</section>
					<section data-background-image="img/sabrina.gif">
						<h2>Girls wear pink</h2>
						<h3 class="fragment">(Normative)</h3>
					</section>
					<section>
						<h2>The way the world is?</h2>
						<h2 class="fragment">or</h2>
						<h2 class="fragment">The way the world should&nbsp;be?</h2>
					</section>
					<section>
						<h2>For example...</h2>
					</section>
					<section data-background-image="img/drone.jpg">
						<aside class="notes">Drone assessing a bridge. It's observing the state of the world (damage to bridge) and the system makes a normative claim: we want to identify and repair damage to bridges! Cracks in bridges are observed in the world (due to various forces of attrition) but not accepted as the inevitable state.</aside>
					</section>
					<section>
						<h2>We make normative assertions all the time</h2>
						<aside class="notes">And it's normal, not interpreted as moralising or judgemental. But we can get squeamish about doing this when it comes to tech ethics. More on this soon.</aside>
					</section>
					<section>
						<h2>Think of the drone...</h2>
						<aside class="notes">If you ever get pushback on making a call like this, think of the drone. Someone designed a rule into the system which identified what was wrong that needed to be repaired. The judgement call is implied. It's the 'status quo' is not good rationale for non-intervention.</aside>
					</section>
					<section>
						<h2>Why should Machine Learning systems be more fair than the data from which they learn?</h2>
						<aside class="notes">Taken from a chat I had with a friend over drinks one night. It's a good question and one I think we need to grapple with to do this work.</aside>
					</section>
					<section>
						<h2>All data is bias</h2>
					</section>
					<section>
						<h2>Some bias is harmful</h2>
					</section>
					<section>
						<h2>Computers can't tell the difference</h2>
					</section>
					<section>
						<h2>ML systems can harden and amplify harmful bias</h2>
						<aside class="notes">Ask for examples of ML bias - give examples if audience doesn't know any.</aside>
					</section>
					<section>
						<h2>Human bias (implicit or explicit) is scoped, the impact limited in a way that machine bias is not</h2>
					</section>
					<section data-background-image="img/janet.gif"></section>
					<section>
						<h2>Issue of scale is also the <br>promise of scale</h2>
						<aside class="notes">One of the shortest routes to the techno-utopian vision is to use the urgency of impact to force us to tackle the work of ethics for ourselves (as individuals) as well as for the machines.</aside>
					</section>
					<section data-background-image="img/janet2.gif">
						<aside class="notes">Technology is fundamentally neutral. It's not moral, or immoral, it's a-moral. Technology is a blank canvas, we are the painters, and the art is all ours.</aside>
					</section>
					<section>
						<h2>Why should we use machines to solve a problem caused by machines?</h2>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>We need technical solutions to solve technical problems at scale</h2>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>For example...</h2>
						<aside class="notes">Example of amount of human time needed to assess and make a judgement about ML classifications from a single model.</aside>
					</section>
					<section>
						<h2>"Machine assisted fairness"</h2>
						<aside class="notes">You heard it here first!</aside>
					</section>
					<section>
						<h2>Computers are great for...</h2>
						<ul>
							<li>Following defined rules</li>
							<li>Stopping at short-circuits</li>
							<li>Computing at scale</li>
						</ul>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>Humans are great for...</h2>
						<ul>
							<li>Pulling the emergency break</li>
							<li>Additional review of tricky use-cases</li>
							<li>Understanding the human impact of a decision</li>
						</ul>
						<aside class="notes"></aside>
					</section>
				</section>
				<section>
					<section>
						<h1>Section 2</h1>
						<h3 class="fragment">Approaches</h3>
						<aside class="notes">What are the ways people are tackling this problem? I divide it into (roughly) three big categories.</aside>
					</section>
					<section>
						<h2>1. Tooling &amp; Tests</h2>
						<aside class="notes">Dev tools, code tests. Looking to mathematical definitions of fairness to help us build dev tools.</aside>
					</section>
					<!-- Proposed ideas like labels and certifications for training data. -->
					<section>
						<ul>
							<li><a href="http://aix360.mybluemix.net" target="_blank">AI Explainability 360</a></li>
							<li><a href="https://aif360.mybluemix.net" target="_blank">AI Fairness 360</a></li>
							<li><a href="https://github.com/marcotcr/lime" target="_blank">Lime</a></li>
							<li><a href="" target="_blank"></a></li>
							<li><a href="" target="_blank"></a></li>
							<li></li>
							<li></li>
							<li>Unit tests?</li>
							<li>CI - "Continuous Inference" - "CAI"</li>
						</ul>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>2A. Academic research</h2>
						<aside class="notes">Conferences, papers, ML research</aside>
					</section>
					<section>
						<ul>
							<li>FAT (fairness, transparency, accountability)</li>
							<li><a href="https://fairxiv.org" target="_blank">fairxiv.org</a></li>
							<li><a href="" target="_blank"></a></li>
							<li>FAT ML</li>
							<li></li>
						</ul>
						<aside class="notes">State of academia (as far as I can tell): 1 step forward, 2 steps backwards</aside>
					</section>
					<section>
						<h1>For example</h1>
						<p class="fragment">Trying to remove gender bias from NLP</p>
						<aside class="notes"></aside>
					</section>
					<section>
						"Man is to Computer Programmer as Woman is to Homemaker?
						Debiasing Word Embeddings"
						<p><a href="https://arxiv.org/pdf/1607.06520.pdf" target="_blank">https://arxiv.org/pdf/1607.06520.pdf</a></p>
						<aside class="notes">Where they tried to flatten (remove) the gender dimension</aside>
					</section>
					<section>
						<h2>Lipstick on a pig</h2>
						<img class="plain" src="img/lipstick.png" height="400" />
						<p><a href="https://arxiv.org/pdf/1903.03862.pdf" target="_blank">https://arxiv.org/pdf/1903.03862.pdf</a></p>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>2B. Self Regulation /<br> Soft Regulation</h2>
						<aside class="notes">Everything that isn't dev tools, research or law</aside>
					</section>
					<section>
						<ul>
							<li><a href="" target="_blank"></a></li>
							<li></li>
							<li><a href="" target="_blank"></a></li>
							<li></li>
						</ul>
						<aside class="notes"></aside>
					</section>
					<section>
						<h2>3. Law / Hard Regulation</h2>
						<aside class="notes"></aside>
					</section>
					<section>
						<ul>
							<li><a href="" target="_blank"></a></li>
							<li></li>
							<li><a href="" target="_blank"></a></li>
							<li></li>
						</ul>
						<aside class="notes"></aside>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
				</section>
				<section>
					<section>
						<h1>Section 3</h1>
						<h3 class="fragment">Fairness definitions</h3>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
				</section>
				<section>
					<section>
						<h1>Section 4</h1>
						<h3 class="fragment">subtitle</h3>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
				</section>
				<section>
					<section>
						<h1>Section 5</h1>
						<h3 class="fragment">subtitle</h3>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
					<section>
						Slide 5
						<aside class="notes"></aside>
					</section>
				</section>
				<section>
					Slide 5
					<aside class="notes"></aside>
				</section>
				<section>
					Slide 6
					<aside class="notes"></aside>
				</section>
				<section>
					Slide 7
					<aside class="notes"></aside>
				</section>
				<!-- <aside class="notes"></aside> -->
			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				backgroundTransition: 'zoom', // none/fade/slide/convex/concave/zoom
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
